<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-dark.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <title>Keep Calm and Carry On</title>
  </head>

  <body>

    <header>
      <div class="container">
        <h1>Keep Calm and Carry On</h1>
        <h2>Voice Stress Recognition Software</h2>

        <section id="downloads">
          <a href="https://github.com/zrahn/SeniorProject/zipball/master" class="btn">Download as .zip</a>
          <a href="https://github.com/zrahn/SeniorProject/tarball/master" class="btn">Download as .tar.gz</a>
          <a href="https://github.com/zrahn/SeniorProject" class="btn btn-github"><span class="icon"></span>View on GitHub</a>
        </section>
      </div>
    </header>

    <div class="container">
      <section id="main_content">
        <h3>
<a id="Summary" class="anchor" href="#Summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Project Summary</h3>

<p>Our project is a machine learning program that will determine, from voice recordings, the amount of stress a person has. Our group is taking 200 voice samples per person for a total of 600 voice samples. Each time we take a voice sample, we record the date, time, stress (yes or no), and the amount of sleep we had. There are other attributes we may record (such as if we drank, if we are sick, if we smoked, if we are on medicine, our blood pressure, heart rate, and body temperature). We process these samples, and the computer will turn the voice samples into a variety of numbers corresponding to different parameters. We will train a machine to recognize when our teammates are stressed, and try to implement a machine learning algorithm that can categorize whether a person is stressed or unstressed from the numbers generated from the voice recognition software. So the ultimate goal of the project is to have a predictive algorithm that can tell if a person is stressed or unstressed from a voice sample.  </p>

<h3>Our Voice Sampling Script</h3>

<p>Do each 3 times:<br>Hold "a" (ah) for 10 seconds.<br>Hold "i" (ee) for 10 seconds.<br>"Pea," "Tea," "Key" 10 times.<br><br>"When the sunlight strikes raindrops in the air, they act as a prism and form a rainbow. The rainbow is a division of white light into many beautiful colors. These take the shape of a long round arch, with its path high above, and its two ends apparently beyond the horizon."<br><br>Then, speak spontaneously for 15 seconds.</p>

<h3>
<a id="links" class="anchor" href="#links" aria-hidden="true"><span class="octicon octicon-link"></span></a>Links</h3>

<p> <a href="https://docs.google.com/spreadsheets/d/1mm08ZrKqVWe3WgDkgBs22OZGA3E-WM3GmGKFGvDn7ww/edit#gid=1" class="burndown-chart">Burndown Chart</a> </p>
<p> <a href="https://www.coursera.org/learn/machine-learning/home/welcome" class="coursera">Stanford Machine Learning Course</a> </p>
<p> <a href="https://drive.google.com/a/villanova.edu/file/d/0By3ooO-hRIBmZlFWb3M5UnpDaXpQSy11V2tVTXpCOXJEQnJv/view" class="research1">Research Paper 1</a> </p>
<p> <a href="https://drive.google.com/a/villanova.edu/file/d/0By3ooO-hRIBmNHk0aUN1eHpKYTRrdWVSRV9wMWNFb1N5Qlkw/view" class="research2">Research Paper 2</a> </p>
<p> <a href="https://drive.google.com/a/villanova.edu/file/d/0By3ooO-hRIBmM3dmY05pNUdvSVMxN2gwOUZ5TWdWUFh5ZXhB/view" class="mdvp1">MDVP Parameters 1</a> </p>
<p> <a href="https://drive.google.com/a/villanova.edu/file/d/0By3ooO-hRIBmT1ZwOTNSVFJueEx0QzBGb1A0NzlCUkNMNzNJ/view" class="mdvp2">MDVP Parameters 2</a> </p>


<h3><a id="week1" class="anchor" href="#week1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Week 1</h3>
<p>Our team researched the topic of our project: Machine Learning. We read two research papers. The first paper, by David Cooper, analyzes audio and video samples in attempts to determine the emotion of each sample. He found that the video was able to determine the subject's emotion accurately, but the audio was too complex. The second paper, by Marcil Boucher, discussed the motor speech impediments associated with autistic children. Boucher analyzed the speech samples from 15 different children using the same script numerous times. The script includes prolongation of two letters, repetition of a short phrase, reading a passage, and speaking spontaneously.</br></p>

<h3><a id="week2" class="anchor" href="#week2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Week 2</h3>
<p>We created our vocal script, and used a similar script that Dr. Boucher used in her dissertation (See script above). Our team determined that we will each take 200 samples using our iPhone voice recorder throughout the semester. Gathering enough samples to train the machine will take the majority of time we spend working on this project. We also created a spreadsheet to record our data We also enrolled in the Stanford Machine Learning Corsera course.</br></p>

<h3><a id="week3" class="anchor" href="#week3" aria-hidden="true"><span class="octicon octicon-link"></span></a>Week 3</h3>
<p>Our team found a softwawre (Multi-Dimensional Voice Program) that takes an audio recording as input, and outputs a text file with a lot of parameters from that audio sample. We will use these numbers that the software outputs, train our machine on the saamples, and come up with a machine learning algorithm that will take a new voice recording and predict the probability of someone being stressed.mdvp software. The Stanford Machine Learning course showed us that this problem could be either a classification problem, but it could also be a regression problem depending on how we collect our data. The algorithm could analyze the voice samples and classify them as either stressed or not stressed. We began taking samples this week, and will continue to take voice recordings until we have enough to train the machine.</br></p>

<h3><a id="week4" class="anchor" href="#week4" aria-hidden="true"><span class="octicon octicon-link"></span></a>Week 4</h3>
<p>Aftertaking a closer look at MDVP, we found various parameters that will be helpful in our project. Some of these parameters include frequency, pitch, and jitter. We continue to take voice recordings, and will see if there is a correlation between some of these parameters and the stress level of the recorder.</br></p>

<h3><a id="week5" class="anchor" href="#week5" aria-hidden="true"><span class="octicon octicon-link"></span></a>Week 5</h3>
<p>Our team tested MDVP on one of our samples. The software processed the voice recording, and wrote the parameters in a text file. We will parse this file and get the data needed for our machine learning algorithm.</br></p>

<h3><a id="week6" class="anchor" href="#week6" aria-hidden="true"><span class="octicon octicon-link"></span></a>Week 6</h3>
<p>The machine learning algorithm we will be using is called Gradient Descent with Backpropagation. This algorithm basically minimizes the error of the cost function. It will attempt to find the global minimum that optimizes our solution. This means that it comes up with an algorithm that has the least amount of error when mapping to our data. We programmed the algorithm in Matlab. We have 28 inputs with the hidden layer being a sigmoid function (that squashes the values between -1 and 1) and the output function is linear. These functions were recommended when setting up our neural network. </br></p>

<h3><a id="week7" class="anchor" href="#week7" aria-hidden="true"><span class="octicon octicon-link"></span></a>Week 7</h3>
<p>We finished gathering our samples this week. Now that we have our samples, we can run them all through MDVP, and have our algorithm train our machine to a specific person's voice. Then when that person takes a voice recording, our algorithm can give a prbability of the chances that person was stressed at the time of the recording. </br></p>

<h3><a id="week8" class="anchor" href="#week8" aria-hidden="true"><span class="octicon octicon-link"></span></a>Week 8</h3>
<p>We trained our algorithm on a random 70% of our data, verified that training on 15% of our data, and the last 15% was used to test how accurate our machine could predict the health statistics based on the voice recording parameters. Our algorithm produced results of about 11-12% error for stress when trying to predict based on the voice recording. Our stress level was on a scale of 1-10, and our algorithm can average within 1 stress level when trying to predict from the voice samples.</br></p>

      </section>
    </div>

    
  </body>
</html>
